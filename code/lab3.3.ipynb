{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d1799c-84ba-4bf8-86ef-4abd9d9c2424",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859fffc-5883-438a-b64f-dea9c9dbfbf1",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "In this step, we use a pre-trained BERT model (bert-base-uncased) to extract CLS token embeddings for each TR (timepoint) in every story. Each TR contains a list of words, which are tokenized and encoded using BERT. These embeddings are then aligned with their corresponding fMRI responses. We apply z-score normalization and temporal delays to the BERT embeddings and fit a ridge regression model to predict voxel-level brain activity from the BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0fc577-d2d8-4c78-849f-bc1b6f2a0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw_text.pkl and fMRI...\n",
      "Valid stories with fMRI: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stories: 100%|██████████| 101/101 [03:18<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected 34700 TRs | BERT dim: 768 | Voxels: 94251\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ridge_utils.utils import zscore, make_delayed\n",
    "from ridge_utils.ridge import ridge_corr\n",
    "\n",
    "# -------------------- Step 1: Loading -------------------- #\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_dir = \"/ocean/projects/mth240012p/shared/data\"\n",
    "subject = \"subject2\"\n",
    "max_tokens = 50\n",
    "\n",
    "print(\"Loading raw_text.pkl and fMRI...\")\n",
    "with open(os.path.join(data_dir, \"raw_text.pkl\"), \"rb\") as f:\n",
    "    raw_texts = pickle.load(f)\n",
    "\n",
    "story_names = []\n",
    "Y_dict = {}\n",
    "for story in raw_texts:\n",
    "    fmri_path = os.path.join(data_dir, subject, f\"{story}.npy\")\n",
    "    if os.path.exists(fmri_path):\n",
    "        Y_dict[story] = np.load(fmri_path)\n",
    "        story_names.append(story)\n",
    "\n",
    "print(f\"Valid stories with fMRI: {len(story_names)}\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # loading BERT Model\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "# -------------------- Step 2: Iterate over each story and each TR -------------------- #\n",
    "X_all, Y_all = [], []\n",
    "\n",
    "for story in tqdm(story_names, desc=\"Processing stories\"):\n",
    "    fmri = Y_dict[story]\n",
    "    ds = raw_texts[story] \n",
    "    for i in range(len(ds.data)):\n",
    "        word_list = ds.data[i] \n",
    "        if not word_list or i >= fmri.shape[0]:\n",
    "            continue  \n",
    "        sentence = \" \".join(word_list)\n",
    "        inputs = tokenizer(\n",
    "            sentence,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        cls_embed = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "        X_all.append(cls_embed)\n",
    "        Y_all.append(fmri[i])\n",
    "\n",
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "print(f\"\\nCollected {X_all.shape[0]} TRs | BERT dim: {X_all.shape[1]} | Voxels: {Y_all.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186a78b1-142a-4176-9616-a678fc9698c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ridge regression...\n",
      "Final shapes → X: (34696, 3840), Y: (34696, 94251)\n",
      "Train: (27756, 3840), Test: (6940, 3840)\n",
      "Ridge correlation shape: (20, 94251)\n",
      "Mean CC:    0.0067\n",
      "Median CC:  0.0065\n",
      "Top 1% CC:  0.0383\n",
      "Top 5% CC:  0.0306\n"
     ]
    }
   ],
   "source": [
    "X_z = zscore(X_all.T).T\n",
    "Y_z = zscore(Y_all)\n",
    "Y_z = np.nan_to_num(Y_z)\n",
    "\n",
    "X_delayed = make_delayed(X_z[4:], delays=[0, 1, 2, 3, 4])\n",
    "Y_trimmed = Y_z[4:]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_delayed, Y_trimmed, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------- Step 3: Ridge Regression -------------------- #\n",
    "print(\"Running ridge regression...\")\n",
    "\n",
    "print(f\"Final shapes → X: {X_delayed.shape}, Y: {Y_trimmed.shape}\")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "alphas = np.logspace(1, 3, 20)\n",
    "ccs = np.array(ridge_corr(X_train, X_test, Y_train, Y_test, alphas))\n",
    "\n",
    "print(\"Ridge correlation shape:\", ccs.shape)\n",
    "best_cc = np.max(ccs, axis=0)\n",
    "print(f\"Mean CC:    {np.mean(best_cc):.4f}\")\n",
    "print(f\"Median CC:  {np.median(best_cc):.4f}\")\n",
    "print(f\"Top 1% CC:  {np.mean(np.sort(best_cc)[-int(0.01*len(best_cc)):]):.4f}\")\n",
    "print(f\"Top 5% CC:  {np.mean(np.sort(best_cc)[-int(0.05*len(best_cc)):]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73440276-29d6-4253-90f1-eed66afd4d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_delayed shape: (34696, 3840)\n",
      "Y_trimmed shape: (34696, 94251)\n",
      "NaN in X: False | Inf in X: False\n",
      "NaN in Y: False | Inf in Y: False\n",
      "X mean/std: 1.3324312972227674e-07 0.9999527897943146\n",
      "Y mean/std: 8.215887372834887e-20 0.9887539174267306\n",
      "All zeros in Y: False\n",
      "Max NaN count per voxel: 776 / 34700\n",
      "Number of voxels with any NaN: 32\n"
     ]
    }
   ],
   "source": [
    "# Check the Result \n",
    "print(\"X_delayed shape:\", X_delayed.shape)\n",
    "print(\"Y_trimmed shape:\", Y_trimmed.shape)\n",
    "print(\"NaN in X:\", np.isnan(X_delayed).any(), \"| Inf in X:\", np.isinf(X_delayed).any())\n",
    "print(\"NaN in Y:\", np.isnan(Y_trimmed).any(), \"| Inf in Y:\", np.isinf(Y_trimmed).any())\n",
    "print(\"X mean/std:\", np.mean(X_delayed), np.std(X_delayed))\n",
    "print(\"Y mean/std:\", np.mean(Y_trimmed), np.std(Y_trimmed))\n",
    "print(\"All zeros in Y:\", np.all(Y_trimmed == 0))\n",
    "nan_voxels = np.isnan(Y_all).sum(axis=0)\n",
    "print(f\"Max NaN count per voxel: {nan_voxels.max()} / {Y_all.shape[0]}\")\n",
    "print(f\"Number of voxels with any NaN: {np.sum(nan_voxels > 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5010a9-40e4-4f29-8c34-eecca0814aef",
   "metadata": {},
   "source": [
    "### Fine-Tuning BERT Encoder on Stimulus Texts\n",
    "\n",
    "In this section, we fine-tune the BERT encoder using the raw story text data via a Masked Language Modeling (MLM) objective.\n",
    "\n",
    "We use the following approach:\n",
    "\n",
    "- **Dataset Construction**: We convert each story's TR-aligned text (from the `DataSequence`) into input IDs for BERT, masking a subset of tokens randomly to form an MLM task. Each TR is treated as one training example.\n",
    "- **Model Architecture**: We reuse the `Encoder` defined in `encoder.py`, which wraps a pre-trained BERT model (`bert-base-uncased`) with a linear decoder head to predict masked tokens.\n",
    "- **Training Loop**: We leverage `train_encoder.py` to fine-tune the model over multiple epochs. The training loss is computed only on masked positions.\n",
    "\n",
    "This fine-tuning step helps the BERT encoder adapt to the linguistic distribution of the experimental stimuli, improving the quality of the learned embeddings for downstream voxel prediction.\n",
    "\n",
    "After training, we will save the encoder weights, which can later be loaded and used for voxel-wise ridge regression in Part 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c886e40-a09e-41b3-b700-1346563f108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset for fine-tuning...\n",
      "Initializing encoder model...\n",
      "Starting MLM training...\n",
      "Epoch [1/3], Train Loss: 1.0625, Val Loss: 0.7735\n",
      "Epoch [2/3], Train Loss: 0.7266, Val Loss: 0.6953\n",
      "Epoch [3/3], Train Loss: 0.6588, Val Loss: 0.6577\n",
      "Fine-tuned encoder saved as 'finetuned_encoder.pt'\n"
     ]
    }
   ],
   "source": [
    "# ======================= Fine-tuning Setup ============================\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from train_encoder import train_bert\n",
    "from encoder import Encoder\n",
    "\n",
    "# 1. Prepare Dataset for MLM pretraining\n",
    "class MLMTextDataset(Dataset):\n",
    "    def __init__(self, raw_texts, tokenizer, max_length=128):\n",
    "        self.samples = []\n",
    "        for story in raw_texts.values():\n",
    "            for word_list in story.data:\n",
    "                if not word_list:\n",
    "                    continue\n",
    "                sentence = \" \".join(word_list)\n",
    "                tokens = tokenizer(\n",
    "                    sentence,\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding='max_length',\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                self.samples.append(tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        return {k: v.squeeze(0) for k, v in item.items()}\n",
    "\n",
    "# 2. Initialize model, tokenizer, and dataset\n",
    "print(\"Preparing dataset for fine-tuning...\")\n",
    "dataset = MLMTextDataset(raw_texts, tokenizer, max_length=128)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(\"Initializing encoder model...\")\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size).to(device)\n",
    "\n",
    "# 3. Train the encoder using MLM objective\n",
    "print(\"Starting MLM training...\")\n",
    "train_bert(\n",
    "    model=encoder,\n",
    "    dataloader=dataloader,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    epochs=3, # Change this if you want\n",
    "    lr=1e-4 # Can change into smaller\n",
    ")\n",
    "\n",
    "# 4. Save encoder for later use\n",
    "torch.save(encoder.state_dict(), \"finetuned_encoder.pt\") # use this model for new BERT Model\n",
    "print(\"Fine-tuned encoder saved as 'finetuned_encoder.pt'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6186a5-a8b4-4a5c-acda-7aea3de2dbdb",
   "metadata": {},
   "source": [
    "## Step 3 Fine-tuning with LoRa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c54340-eb64-431a-ae55-9abcdc2003af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, os\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True   # TF32 for faster matmul\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d71d78-b6ae-4244-b4d7-3d0866d523c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mean/std: 2.559960858049071e-18 1.0\n"
     ]
    }
   ],
   "source": [
    "voxel_idx = 0                       # <— change voxel here\n",
    "\n",
    "X_train_text = X_train              # list[str]\n",
    "X_test_text  = X_test\n",
    "\n",
    "y_train_v = Y_train[:, voxel_idx]\n",
    "y_test_v  = Y_test[:,  voxel_idx]\n",
    "\n",
    "mu, sd    = y_train_v.mean(), y_train_v.std()\n",
    "y_train_z = (y_train_v - mu) / sd\n",
    "y_test_z  = (y_test_v  - mu) / sd\n",
    "\n",
    "print(\"Label mean/std:\", y_train_z.mean(), y_train_z.std())   # ≈0 / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0f3ed2-46f3-4880-ba4e-dfb0e1fa993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31230 train  /  3470 valid sentences\n"
     ]
    }
   ],
   "source": [
    "# --- Pick a voxel & build TR-aligned sentences -------------\n",
    "voxel_idx = 0          # choose voxel to predict\n",
    "train_split = 0.9\n",
    "\n",
    "sentences, labels = [], []\n",
    "for story in story_names:                # story_names from your earlier code\n",
    "    fmri = Y_dict[story]                 # (n_TR, n_voxels)\n",
    "    ds   = raw_texts[story]              # word lists per TR\n",
    "    for tr, word_list in enumerate(ds.data):\n",
    "        if not word_list or tr >= fmri.shape[0]:\n",
    "            continue\n",
    "        sentences.append(\" \".join(word_list))\n",
    "        labels.append(float(fmri[tr, voxel_idx]))\n",
    "\n",
    "# ---- shuffle & train/valid split --------------------------\n",
    "idx = np.random.RandomState(42).permutation(len(sentences))\n",
    "sentences = [sentences[i] for i in idx]\n",
    "labels    = np.array(labels)[idx]\n",
    "\n",
    "split = int(train_split * len(sentences))\n",
    "train_text, test_text  = sentences[:split],  sentences[split:]\n",
    "train_label, test_label = labels[:split],    labels[split:]\n",
    "\n",
    "print(f\"{len(train_text)} train  /  {len(test_text)} valid sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a62af0-00d9-4745-8433-257bd32f93e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mean/std after z-score: 2.047673590086744e-17 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "mu, sd = train_label.mean(), train_label.std()\n",
    "train_z = (train_label - mu) / sd\n",
    "test_z  = (test_label  - mu) / sd\n",
    "print(\"Label mean/std after z-score:\", train_z.mean(), train_z.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1929cab1-cdb8-4c74-b679-1bf46f15852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = tokenizer(train_text, truncation=True,\n",
    "                      padding=\"max_length\", max_length=128)\n",
    "test_enc  = tokenizer(test_text,  truncation=True,\n",
    "                      padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_ds = Dataset.from_dict({\n",
    "    \"input_ids\"     : train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"labels\"        : train_z.astype(np.float32),\n",
    "}).with_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "test_ds = Dataset.from_dict({\n",
    "    \"input_ids\"     : test_enc[\"input_ids\"],\n",
    "    \"attention_mask\": test_enc[\"attention_mask\"],\n",
    "    \"labels\"        : test_z.astype(np.float32),\n",
    "}).with_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc60acb-ebcf-49e4-bf29-55ee956f4ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,180,417 || all params: 110,663,426 || trainable%: 1.0667\n"
     ]
    }
   ],
   "source": [
    "base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=1, problem_type=\"regression\"\n",
    ")\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=32, lora_alpha=32, target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "model = get_peft_model(base, lora_cfg).to(device)\n",
    "\n",
    "# freeze everything except LoRA & regressor\n",
    "for n, p in model.named_parameters():\n",
    "    if (\"lora_\" not in n) and (\"classifier\" not in n):\n",
    "        p.requires_grad = False\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492e3491-9c7c-47d8-9a7c-0415f7069bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32432/973216098.py:39: UserWarning: Transformer version doesn’t support ['evaluation_strategy', 'fp16', 'learning_rate', 'logging_steps', 'num_train_epochs', 'optim', 'output_dir', 'per_device_eval_batch_size', 'per_device_train_batch_size', 'seed', 'warmup_steps', 'weight_decay']; dropped them.\n",
      "  warnings.warn(f\"Transformer version doesn’t support {sorted(dropped)}; dropped them.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments compiled with 13 keywords\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "import inspect, torch, numpy as np, warnings\n",
    "\n",
    "# ---------- hyper-params ----------\n",
    "BATCH = 32          \n",
    "EPOCHS = 5\n",
    "LR     = 1e-5\n",
    "# -----------------------------------------------\n",
    "\n",
    "total_steps  = int(np.ceil(len(train_ds) / BATCH) * EPOCHS)\n",
    "warmup_steps = int(0.05 * total_steps)\n",
    "\n",
    "base_kwargs = dict(\n",
    "    output_dir                  = \"lora-regression\",\n",
    "    per_device_train_batch_size = BATCH,\n",
    "    per_device_eval_batch_size  = BATCH,\n",
    "    num_train_epochs            = EPOCHS,\n",
    "    learning_rate               = LR,\n",
    "    warmup_steps                = warmup_steps,\n",
    "    weight_decay                = 0.01,\n",
    "    logging_steps               = 100,\n",
    "    seed                        = 42,\n",
    "    fp16                        = torch.cuda.is_available(),\n",
    "    optim                       = \"adamw_torch_fused\",\n",
    ")\n",
    "\n",
    "extra = {\n",
    "    \"save_strategy\"      : \"no\",\n",
    "    \"evaluation_strategy\": \"no\",\n",
    "    \"dataloader_num_workers\": 4,\n",
    "}\n",
    "\n",
    "sig = inspect.signature(TrainingArguments.__init__)\n",
    "allowed = {k: v for k, v in {**base_kwargs, **extra}.items()\n",
    "           if k in sig.parameters}\n",
    "\n",
    "dropped = set(base_kwargs) | set(extra) - set(allowed)\n",
    "if dropped:\n",
    "    warnings.warn(f\"Transformer version doesn’t support {sorted(dropped)}; dropped them.\")\n",
    "\n",
    "train_args = TrainingArguments(**allowed)\n",
    "print(\"TrainingArguments compiled with\", len(allowed), \"keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82302c71-cf2b-4f0a-851a-6c464ce9da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_32432/1010594794.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4880' max='4880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4880/4880 01:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.981500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.957500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.993900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.975300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.962200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.978900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.966300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.989600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>1.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.005200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4880, training_loss=1.0161433251177678, metrics={'train_runtime': 102.1694, 'train_samples_per_second': 1528.344, 'train_steps_per_second': 47.764, 'total_flos': 1.04126649866496e+16, 'train_loss': 1.0161433251177678, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n",
    "def r2_metric(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.squeeze()\n",
    "    r2 = 1.0 - np.mean((labels - preds) ** 2)   # on z-scored labels\n",
    "    return {\"r2\": r2}\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=r2_metric,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796d6706-36c7-4b7c-af4a-14e4815af971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel 0  –  R² = 0.0001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "preds = trainer.predict(test_ds).predictions.squeeze()\n",
    "r2    = r2_score(test_z, preds)          # test_z from Mini-Cell B\n",
    "print(f\"Voxel {voxel_idx}  –  R² = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5928bfa6-6ebb-4f5b-9f29-7dba2536bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings: (190401, 768)\n"
     ]
    }
   ],
   "source": [
    "# --- load the trained model (adapter + base) ---\n",
    "model.eval()\n",
    "\n",
    "all_cls = []\n",
    "with torch.no_grad():\n",
    "    for story in story_names:\n",
    "        ds   = raw_texts[story]\n",
    "        for word_list in ds.data:\n",
    "            if not word_list:\n",
    "                continue\n",
    "            text = \" \".join(word_list)\n",
    "            tok  = tokenizer(text, return_tensors=\"pt\",\n",
    "                             padding=\"max_length\", truncation=True,\n",
    "                             max_length=128).to(device)\n",
    "            hidden = model.bert(**tok).last_hidden_state[:,0,:]   # CLS\n",
    "            all_cls.append(hidden.squeeze().cpu().numpy())\n",
    "\n",
    "all_cls = np.array(all_cls)          # (n_TR, 768)\n",
    "np.save(\"lora_cls_subject2.npy\", all_cls)\n",
    "print(\"Saved embeddings:\", all_cls.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "889c12ea-574c-4a94-847f-399681d326a5",
   "metadata": {},
   "source": [
    "## Run Ridge Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66afd424-bd7c-4e37-b630-c1d962e6625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34700, 768) (34700, 94251)\n"
     ]
    }
   ],
   "source": [
    "embeds   = []\n",
    "fmri_rows = []\n",
    "\n",
    "for story in story_names:\n",
    "    ds   = raw_texts[story]\n",
    "    fmri = Y_dict[story]\n",
    "\n",
    "    for tr, word_list in enumerate(ds.data):\n",
    "        if not word_list or tr >= fmri.shape[0]:\n",
    "            continue           \n",
    "\n",
    "        sent = \" \".join(word_list)\n",
    "        tok  = tokenizer(sent, return_tensors=\"pt\",\n",
    "                         padding=\"max_length\", truncation=True,\n",
    "                         max_length=128).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            cls = model.bert(**tok).last_hidden_state[:, 0, :].squeeze()\n",
    "\n",
    "        embeds.append(cls.cpu().numpy())\n",
    "        fmri_rows.append(fmri[tr])\n",
    "X_all = np.asarray(embeds)       # shape (N_keep, 768)\n",
    "Y_all = np.asarray(fmri_rows)    # shape (N_keep, n_voxels)\n",
    "print(X_all.shape, Y_all.shape)  # should have identical first dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cbd8ee9-f492-4add-8119-7ba81e3b9a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('results/lora_model/tokenizer_config.json',\n",
       " 'results/lora_model/special_tokens_map.json',\n",
       " 'results/lora_model/vocab.txt',\n",
       " 'results/lora_model/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"results/lora_model\"      \n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(save_dir)         # save adapter config + weights\n",
    "tokenizer.save_pretrained(save_dir)     # same vocab / padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "433eb593-57f7-4f1c-a997-efb521aaef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design: (34696, 3840)   fMRI: (34696, 94251)\n",
      "processed voxels      0-9999    chunk mean CC = 0.3143\n",
      "processed voxels  10000-19999   chunk mean CC = 0.3154\n",
      "processed voxels  20000-29999   chunk mean CC = 0.3154\n",
      "processed voxels  30000-39999   chunk mean CC = 0.3153\n",
      "processed voxels  40000-49999   chunk mean CC = 0.3152\n",
      "processed voxels  50000-59999   chunk mean CC = 0.3150\n",
      "processed voxels  60000-69999   chunk mean CC = 0.3150\n",
      "processed voxels  70000-79999   chunk mean CC = 0.3151\n",
      "processed voxels  80000-89999   chunk mean CC = 0.3152\n",
      "processed voxels  90000-94250   chunk mean CC = 0.3151\n",
      "\n",
      "Done in 784.8 s\n",
      "Mean   CC (LoRA) : 0.3151\n",
      "Median CC (LoRA) : 0.3152\n",
      "Top 1% CC (LoRA) : 0.3253\n",
      "Top 5% CC (LoRA) : 0.3230\n"
     ]
    }
   ],
   "source": [
    "# === Fast z-score, delay, and chunked ridge for LoRA embeddings =========\n",
    "import numpy as np, logging, time\n",
    "from ridge_utils.ridge import ridge_corr\n",
    "from ridge_utils.utils import make_delayed  \n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# ----- 1. vectorised z-score (float32) ----------------------------------\n",
    "X32 = X_all.astype(np.float32)\n",
    "X_z = (X32 - X32.mean(0, keepdims=True)) / (X32.std(0, keepdims=True) + 1e-10)\n",
    "\n",
    "Y32 = Y_all.astype(np.float32)\n",
    "Y_z = (Y32 - Y32.mean(0, keepdims=True)) / (Y32.std(0, keepdims=True) + 1e-10)\n",
    "\n",
    "# ----- 2. temporal delays ------------------------------------------------\n",
    "X_del  = make_delayed(X_z[4:], delays=[0,1,2,3,4]).astype(np.float32)\n",
    "Y_trim = Y_z[4:].astype(np.float32)\n",
    "print(\"Design:\", X_del.shape, \"  fMRI:\", Y_trim.shape)\n",
    "\n",
    "# ----- 3. chunked ridge --------------------------------------------------\n",
    "alphas = np.logspace(1, 3, 20).astype(np.float32)\n",
    "chunk  = 10_000          \n",
    "\n",
    "# dummy logger to satisfy ridge_corr\n",
    "log = logging.getLogger(\"ridge-dummy\")\n",
    "log.addHandler(logging.NullHandler())\n",
    "\n",
    "best_ccs = []\n",
    "for start in range(0, Y_trim.shape[1], chunk):\n",
    "    stop = min(start + chunk, Y_trim.shape[1])\n",
    "\n",
    "    cc_list = ridge_corr(                \n",
    "        X_del, X_del,\n",
    "        Y_trim[:, start:stop], Y_trim[:, start:stop],\n",
    "        alphas,\n",
    "        use_corr=True,\n",
    "        logger=log,\n",
    "    )\n",
    "    cc      = np.asarray(cc_list)       \n",
    "    best_ccs.append(cc.max(axis=0))      \n",
    "\n",
    "    print(f\"processed voxels {start:>6}-{stop-1:<6}  \"\n",
    "          f\"chunk mean CC = {cc.max(axis=0).mean():.4f}\", flush=True)\n",
    "\n",
    "best_cc = np.concatenate(best_ccs)\n",
    "\n",
    "# --- top-k summaries ----------------------------------------------\n",
    "top1  = best_cc[np.argpartition(best_cc, -int(0.01*len(best_cc)))[-int(0.01*len(best_cc)):]].mean()\n",
    "top5  = best_cc[np.argpartition(best_cc, -int(0.05*len(best_cc)))[-int(0.05*len(best_cc)):]].mean()\n",
    "\n",
    "print(f\"\\nDone in {time.time() - t0:.1f} s\")\n",
    "print(f\"Mean   CC (LoRA) : {best_cc.mean():.4f}\")\n",
    "print(f\"Median CC (LoRA) : {np.median(best_cc):.4f}\")\n",
    "print(f\"Top 1% CC (LoRA) : {top1:.4f}\")\n",
    "print(f\"Top 5% CC (LoRA) : {top5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7ff7c",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a561b31-b4e0-48bc-90df-1bbc098597a8",
   "metadata": {},
   "source": [
    "# 1) Identifying voxels where the model performs well"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80fb0b67-39ed-41de-ae69-270dbd902e5c",
   "metadata": {},
   "source": [
    "Required work from part 1: \n",
    "\n",
    "Once final encoder model has been trained (LORA?), then we use that encoder model to create embeddings and run ridge regression on only a single story. Then we want to save those correlation coefficient results to our folder as ridge_corr_subject2.npy. Then once that is commplete, the following code should run fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af61638-2a84-4bef-9f23-6ac421b1b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/ocean/projects/mth240012p/shared/data\"\n",
    "subject = \"subject2\"\n",
    "story = \"myfathershands\"\n",
    "\n",
    "# Load the raw_text.pkl\n",
    "with open(os.path.join(data_dir, \"raw_text.pkl\"), \"rb\") as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "# Load fMRI data only for selected story\n",
    "fmri_path = os.path.join(data_dir, subject, f\"{story}.npy\")\n",
    "assert os.path.exists(fmri_path), f\"{story}.npy not found\"\n",
    "Y_story = np.load(fmri_path)\n",
    "\n",
    "print(\"Loaded story:\", story, \"| fMRI shape:\", Y_story.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be3d92-7f50-4c19-af1a-d2c2a433ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from encoder import Encoder\n",
    "from ridge_utils.utils import make_delayed, zscore\n",
    "from ridge_utils.ridge import ridge_corr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------\n",
    "# Setup\n",
    "# ---------------------\n",
    "data_dir = \"/ocean/projects/mth240012p/shared/data\"\n",
    "subject = \"subject2\"\n",
    "# story = \"stagefright\"\n",
    "story = \"myfathershands\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------------\n",
    "# Load raw_text and fMRI for one story\n",
    "# ---------------------\n",
    "with open(os.path.join(data_dir, \"raw_text.pkl\"), \"rb\") as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "Y_story = np.load(os.path.join(data_dir, subject, f\"{story}.npy\"))\n",
    "\n",
    "# ---------------------\n",
    "# Load encoder and tokenizer\n",
    "# ---------------------\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size)\n",
    "encoder.load_state_dict(torch.load(\"finetuned_encoder.pt\", map_location=device))\n",
    "encoder.to(device).eval()\n",
    "\n",
    "# ---------------------\n",
    "# Get sentence embeddings\n",
    "# ---------------------\n",
    "X_story, Y_rows = [], []\n",
    "with torch.no_grad():\n",
    "    for tr, word_list in enumerate(raw_text[story].data):\n",
    "        if not word_list or tr >= Y_story.shape[0]:\n",
    "            continue\n",
    "        sentence = \" \".join(word_list)\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "        hidden = encoder(**inputs)  # shape: (1, seq_len, hidden_dim)\n",
    "        cls = hidden[:, 0, :]       # CLS token\n",
    "        X_story.append(cls.squeeze().cpu().numpy())\n",
    "        Y_rows.append(Y_story[tr])\n",
    "\n",
    "X_story = np.array(X_story)\n",
    "Y_story = np.array(Y_rows)\n",
    "\n",
    "# ---------------------\n",
    "# Normalize + delay\n",
    "# ---------------------\n",
    "X_z = zscore(X_story.T).T\n",
    "Y_z = zscore(Y_story)\n",
    "Y_z = np.nan_to_num(Y_z)\n",
    "\n",
    "X_del = make_delayed(X_z[4:], delays=[0,1,2,3,4])\n",
    "Y_trim = Y_z[4:]\n",
    "\n",
    "# ---------------------\n",
    "# Split\n",
    "# ---------------------\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_del, Y_trim, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Ridge regression\n",
    "# ---------------------\n",
    "print(\"Running ridge regression...\")\n",
    "alphas = np.logspace(1, 3, 20)\n",
    "ccs = np.array(ridge_corr(X_train, X_test, Y_train, Y_test, alphas))\n",
    "\n",
    "# ---------------------\n",
    "# Summary\n",
    "# ---------------------\n",
    "best_cc = np.max(ccs, axis=0)\n",
    "print(\"Ridge correlation shape:\", ccs.shape)\n",
    "print(f\"Mean CC:    {np.mean(best_cc):.4f}\")\n",
    "print(f\"Median CC:  {np.median(best_cc):.4f}\")\n",
    "print(f\"Top 1% CC:  {np.mean(np.sort(best_cc)[-int(0.01 * len(best_cc)):]):.4f}\")\n",
    "print(f\"Top 5% CC:  {np.mean(np.sort(best_cc)[-int(0.05 * len(best_cc)):]):.4f}\")\n",
    "\n",
    "# ---------------------\n",
    "# Save result (optional)\n",
    "# ---------------------\n",
    "np.save(\"/tmp/ridge_corr_myfathershands.npy\", ccs)\n",
    "print(\"Saved ridge_corr_myfathershands.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ccc244-d7bd-4cfa-9d81-b11a1683d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Load ridge correlation results for myfathershands\n",
    "ccs = np.load(\"/tmp/ridge_corr_myfathershands.npy\")  # shape: (num_alphas, num_voxels)\n",
    "best_cc = np.max(ccs, axis=0)  # best correlation per voxel\n",
    "\n",
    "# Select top 10 voxels\n",
    "top_voxel_indices = np.argsort(best_cc)[-10:][::-1]\n",
    "\n",
    "print(\"Top 10 voxel indices selected for interpretation:\")\n",
    "print(top_voxel_indices)\n",
    "print(\"Top 10 voxel correlation scores:\")\n",
    "print(best_cc[top_voxel_indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebaabc4-e2be-40f4-9d7e-1130a2482058",
   "metadata": {},
   "source": [
    "# Running SHAP and LIME to Identigy Influential Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import Ridge\n",
    "from transformers import BertTokenizer\n",
    "from encoder import Encoder\n",
    "from ridge_utils.utils import zscore, make_delayed\n",
    "from ridge_utils.ridge import ridge_corr\n",
    "\n",
    "# --- Setup ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_dir = \"/ocean/projects/mth240012p/shared/data\"\n",
    "subject = \"subject2\"\n",
    "story = \"myfathershands\"\n",
    "\n",
    "# --- Load raw text ---\n",
    "with open(os.path.join(data_dir, \"raw_text.pkl\"), \"rb\") as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "# --- Load fMRI ---\n",
    "Y_dict = {}\n",
    "Y_dict[story] = np.load(os.path.join(data_dir, subject, f\"{story}.npy\"))\n",
    "\n",
    "# --- Load fine-tuned encoder ---\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size)\n",
    "encoder.load_state_dict(torch.load(\"finetuned_encoder.pt\", map_location=device))\n",
    "encoder.to(device).eval()\n",
    "\n",
    "# --- Get embeddings + fMRI for this story ---\n",
    "X_story = []\n",
    "Y_story_rows = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tr, word_list in enumerate(raw_text[story].data):\n",
    "        if not word_list or tr >= Y_dict[story].shape[0]:\n",
    "            continue\n",
    "        sentence = \" \".join(word_list)\n",
    "        tok = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "        hidden = encoder(**tok)\n",
    "        cls = hidden[:, 0, :]\n",
    "        X_story.append(cls.squeeze().cpu().numpy())\n",
    "        Y_story_rows.append(Y_dict[story][tr])\n",
    "\n",
    "X_story = np.array(X_story)\n",
    "Y_story = np.array(Y_story_rows)\n",
    "\n",
    "# --- Z-score + delay ---\n",
    "X_z = zscore(X_story.T).T\n",
    "Y_z = zscore(Y_story)\n",
    "Y_z = np.nan_to_num(Y_z)\n",
    "X_del = make_delayed(X_z[4:], delays=[0, 1, 2, 3, 4])\n",
    "Y_trim = Y_z[-X_del.shape[0]:]\n",
    "\n",
    "# --- Ridge regression on all voxels ---\n",
    "alphas = np.logspace(1, 3, 20)\n",
    "ccs = np.array(ridge_corr(X_del, X_del, Y_trim, Y_trim, alphas))\n",
    "best_cc = np.max(ccs, axis=0)\n",
    "\n",
    "# --- Select top voxel ---\n",
    "top_voxel_indices = np.argsort(best_cc)[-10:][::-1]\n",
    "top_voxel = top_voxel_indices[0]\n",
    "print(\"Top voxel:\", top_voxel)\n",
    "\n",
    "# --- Fit Ridge model for that voxel ---\n",
    "alpha_best = alphas[np.argmax(ccs[:, top_voxel])]\n",
    "model = Ridge(alpha=alpha_best).fit(X_del, Y_trim[:, top_voxel])\n",
    "\n",
    "# --- SHAP Explanation ---\n",
    "explainer = shap.Explainer(model.predict, X_del[:100])\n",
    "shap_values = explainer(X_del[:100], max_evals=2 * X_del.shape[1] + 1)\n",
    "\n",
    "# --- Sentence list aligned to delayed input ---\n",
    "sentence_lists = [w for w in raw_text[story].data if w][4:]\n",
    "\n",
    "# --- Compute word-level importance ---\n",
    "def aggregate_shap_importance(shap_values, sentence_lists, delay=5):\n",
    "    word_contribs = defaultdict(float)\n",
    "    num_examples, total_dim = shap_values.values.shape\n",
    "    d = total_dim // delay\n",
    "    for i in range(num_examples):\n",
    "        shap_vec = shap_values.values[i]\n",
    "        for d_idx in range(delay):\n",
    "            vec = shap_vec[d_idx * d: (d_idx + 1) * d]\n",
    "            words = sentence_lists[i + d_idx].split()  # ✅ split sentence into words\n",
    "            if not words:\n",
    "                continue\n",
    "            contrib = np.sum(np.abs(vec)) / len(words)\n",
    "            for word in words:\n",
    "                word_contribs[word] += contrib\n",
    "    return word_contribs\n",
    "\n",
    "\n",
    "word_contribs = aggregate_shap_importance(shap_values, sentence_lists)\n",
    "\n",
    "# --- Plot top 20 words ---\n",
    "top_words = sorted(word_contribs.items(), key=lambda x: -x[1])[:20]\n",
    "words, scores = zip(*top_words)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(words, scores, color=\"green\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(f\"Top 20 Most Influential Words for Voxel {top_voxel}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da226a-3e75-4f4d-8cde-a1fe0e889444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.linear_model import Ridge\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# 1. Fit Ridge Model for a Top Voxel\n",
    "# -----------------------\n",
    "print(\"Step 1: Fitting Ridge model for top voxel...\")\n",
    "voxel_idx = top_voxel_indices[0]\n",
    "alpha_best = np.logspace(1, 3, 20)[np.argmax(ccs, axis=0)]\n",
    "model = Ridge(alpha=alpha_best[voxel_idx])\n",
    "model.fit(X_del, Y_trim[:, voxel_idx])\n",
    "\n",
    "# -----------------------\n",
    "# 2. Define LIME Explainer\n",
    "# -----------------------\n",
    "\n",
    "print(\"Step 2: Setting up LIME explainer and tokenizer...\")\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import re\n",
    "\n",
    "explainer = LimeTextExplainer(\n",
    "    class_names=[\"voxel activation\"],\n",
    "    char_level=False,\n",
    "    split_expression=r\"\\s+\"  # splits only on spaces\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# TR-aligned sentences\n",
    "# LIME needs full sentences for tokenization — align with delayed X\n",
    "sentence_texts = []\n",
    "for i in range(4, len(raw_text[story].data) - 4):\n",
    "    sentence_words = []\n",
    "    for j in range(i-4, i+1):  # match the 5-TR delay\n",
    "        word_chars = raw_text[story].data[j]\n",
    "        if word_chars:\n",
    "            word = \"\".join(word_chars)  # ✅ join chars into word\n",
    "            sentence_words.append(word)\n",
    "    sentence_texts.append(\" \".join(sentence_words))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3. Define predict function\n",
    "# -----------------------\n",
    "def predict_fn(texts):\n",
    "    embeddings = []\n",
    "    for t in texts:\n",
    "        inputs = tokenizer(t, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            cls_emb = encoder(**inputs)[:, 0, :].cpu().numpy()  # shape (1, 256)\n",
    "        delayed_emb = np.tile(cls_emb, (1, 5))  # shape (1, 1280)\n",
    "        embeddings.append(delayed_emb)\n",
    "    return model.predict(np.vstack(embeddings)).reshape(-1, 1)  # reshape for LIME\n",
    "\n",
    "# -----------------------\n",
    "# 4. Run LIME on Sampled Sentences\n",
    "# -----------------------\n",
    "\n",
    "print(\"Step 3: Running LIME explanations...\")\n",
    "word_scores = defaultdict(float)\n",
    "num_samples = 100  # for speed\n",
    "\n",
    "for i in range(min(num_samples, len(sentence_texts))):\n",
    "    exp = explainer.explain_instance(sentence_texts[i], predict_fn, labels=[0], num_features=10)\n",
    "    for word, weight in exp.as_list(label=0):\n",
    "        word_scores[word] += abs(weight)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Plot LIME Results\n",
    "# -----------------------\n",
    "\n",
    "print(\"Step 4: Plotting results...\")\n",
    "sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "words, scores = zip(*sorted_words)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, scores, color=\"orange\")\n",
    "plt.title(f\"Top 20 Most Influential Words by LIME for Voxel {voxel_idx}\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b19f8ee-561e-42e2-93d0-f9018cb3d1df",
   "metadata": {},
   "source": [
    "# Comparing SHAP and LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555706f-2643-4974-a9f3-1909c781b404",
   "metadata": {},
   "source": [
    "Required work:\n",
    "\n",
    "We will add side-by-side comparisons and try across a couple more voxels. could have something like the following:\n",
    "\n",
    "EXAMPLE CODE\n",
    "<!-- \n",
    "def compare_word_importance(shap_values, lime_exp, voxel_idx):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # SHAP bar plot\n",
    "    shap.plots.bar(shap_values[:, :, voxel_idx].mean(0), show=False, ax=axes[0])\n",
    "    axes[0].set_title(f\"SHAP - Voxel {voxel_idx}\")\n",
    "    \n",
    "    # LIME bar plot\n",
    "    lime_exp.as_pyplot_figure(axes[1])\n",
    "    axes[1].set_title(f\"LIME - Voxel {voxel_idx}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "compare_word_importance(shap_values, lime_exp, voxel_idx=0)\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3b42c-2212-4a0c-a5b2-0cff9e0790e7",
   "metadata": {},
   "source": [
    "# Repeat all analysis for another test-story"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21884b3a-0045-4ae6-a3d2-6f934041caad",
   "metadata": {},
   "source": [
    "Required work:\n",
    "\n",
    "just repeat all code shown above but for a new story and compare the word importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ea46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just change the story name and re-run Section 2 onward??? not sure\n",
    "story_name = \"myfirstdaywiththeyankees\"\n",
    "sentences = [\" \".join(w) for w in raw_text[story_name].data if len(w) > 0][:50]\n",
    "\n",
    "# Rerun: predict_voxel_activation(), SHAP, and LIME\n",
    "shap_values = shap_explainer(sentences)\n",
    "shap.plots.text(shap_values[0])\n",
    "lime_exp = lime_explainer.explain_instance(sentences[0], predict_voxel_activation, num_features=10)\n",
    "lime_fig = lime_exp.as_pyplot_figure()\n",
    "plt.title(\"LIME Word Importance for Another Sentence (Voxel-Level)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
