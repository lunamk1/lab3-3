{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc0fc577-d2d8-4c78-849f-bc1b6f2a0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw_text.pkl and fMRI...\n",
      "Valid stories with fMRI: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stories: 100%|██████████| 101/101 [40:25<00:00, 24.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected 34700 TRs | BERT dim: 768 | Voxels: 94251\n",
      "Running ridge regression...\n",
      "Ridge correlation shape: (20, 94251)\n",
      "Mean CC:    0.0000\n",
      "Median CC:  0.0000\n",
      "Top 1% CC:  0.0000\n",
      "Top 5% CC:  0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ridge_utils.utils import zscore, make_delayed\n",
    "from ridge_utils.ridge import ridge_corr\n",
    "\n",
    "# -------------------- Step 1: 配置 -------------------- #\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_dir = \"/ocean/projects/mth240012p/shared/data\"\n",
    "subject = \"subject2\"\n",
    "max_tokens = 50\n",
    "\n",
    "# -------------------- Step 2: 加载原始文本和 fMRI -------------------- #\n",
    "print(\"Loading raw_text.pkl and fMRI...\")\n",
    "with open(os.path.join(data_dir, \"raw_text.pkl\"), \"rb\") as f:\n",
    "    raw_texts = pickle.load(f)\n",
    "\n",
    "story_names = []\n",
    "Y_dict = {}\n",
    "for story in raw_texts:\n",
    "    fmri_path = os.path.join(data_dir, subject, f\"{story}.npy\")\n",
    "    if os.path.exists(fmri_path):\n",
    "        Y_dict[story] = np.load(fmri_path)\n",
    "        story_names.append(story)\n",
    "\n",
    "print(f\"Valid stories with fMRI: {len(story_names)}\")\n",
    "\n",
    "# -------------------- Step 3: 加载 BERT 模型 -------------------- #\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "# -------------------- Step 4: 遍历每个 story → 每个 TR -------------------- #\n",
    "X_all, Y_all = [], []\n",
    "\n",
    "for story in tqdm(story_names, desc=\"Processing stories\"):\n",
    "    fmri = Y_dict[story]\n",
    "    ds = raw_texts[story]  # ✅ DataSequence 对象\n",
    "    for i in range(len(ds.data)):\n",
    "        word_list = ds.data[i]  # ✅ 兼容 __getitem__\n",
    "        if not word_list or i >= fmri.shape[0]:\n",
    "            continue  # 跳过空 TR 或 fMRI 数据缺失\n",
    "        sentence = \" \".join(word_list)\n",
    "        inputs = tokenizer(\n",
    "            sentence,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        cls_embed = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "        X_all.append(cls_embed)\n",
    "        Y_all.append(fmri[i])\n",
    "\n",
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "print(f\"\\nCollected {X_all.shape[0]} TRs | BERT dim: {X_all.shape[1]} | Voxels: {Y_all.shape[1]}\")\n",
    "\n",
    "# -------------------- Step 5: Z-score 和划分 Train/Test -------------------- #\n",
    "X_z = zscore(X_all.T).T\n",
    "Y_z = zscore(Y_all)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_z, Y_z, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------------------- Step 6: Ridge Regression -------------------- #\n",
    "print(\"Running ridge regression...\")\n",
    "alphas = np.logspace(1, 3, 20)\n",
    "ccs = np.array(ridge_corr(make_delayed(X_train, [0,1,2,3,4]),\n",
    "                          make_delayed(X_test, [0,1,2,3,4]),\n",
    "                          Y_train, Y_test, alphas))\n",
    "\n",
    "# -------------------- Step 7: 输出结果 -------------------- #\n",
    "print(\"Ridge correlation shape:\", ccs.shape)\n",
    "best_cc = np.max(ccs, axis=0)\n",
    "print(f\"Mean CC:    {np.mean(best_cc):.4f}\")\n",
    "print(f\"Median CC:  {np.median(best_cc):.4f}\")\n",
    "print(f\"Top 1% CC:  {np.mean(np.sort(best_cc)[-int(0.01*len(best_cc)):]):.4f}\")\n",
    "print(f\"Top 5% CC:  {np.mean(np.sort(best_cc)[-int(0.05*len(best_cc)):]):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
